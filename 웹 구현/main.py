import streamlit as st
from PIL import Image
import torch 
from transformers import AutoModelForPreTraining, PreTrainedTokenizerFast
from typing import Optional


device = torch.device('cpu')

tokenizer = PreTrainedTokenizerFast.from_pretrained("skt/kogpt2-base-v2",
                                                    bos_token='<s>', eos_token='</s>', unk_token='<unk>',
                                                    pad_token='<pad>', mask_token='<mask>', padding_side='right')      

tokenizer.vocab['<unused0>'] = '<yun>'
model = AutoModelForPreTraining.from_pretrained("skt/kogpt2-base-v2")


def model_load(poet):
    if poet == 'ê¸°ë³¸ëª¨ë¸':
        model.load_state_dict(torch.load('19000model.pth', map_location=device))
        
    elif poet == 'ìœ¤ë™ì£¼':
        model.load_state_dict(torch.load('ìœ¤ë™ì£¼.pth', map_location=device))
 
    elif poet == 'ì´í•´ì¸ ìˆ˜ë…€ë‹˜':
        model.load_state_dict(torch.load('ì´í•´ì¸ ìˆ˜ë…€ë‹˜.pth', map_location=device))
        
    else:
        model.load_state_dict(torch.load('ë²•ì •ìŠ¤ë‹˜.pth', map_location=device))


def gpt(prompt, min, max, rept_penalty):       

    #ìƒì„± 
    prompt_ids = tokenizer.encode(prompt)
    inp = torch.tensor(prompt_ids)[None].cpu()
    preds = model.generate(inp,              
                           min_length=min,
                           max_length=max,
                           do_sample = True,
                           pad_token_id=tokenizer.pad_token_id,
                           eos_token_id=tokenizer.eos_token_id,
                           bos_token_id=tokenizer.bos_token_id,
                           length_penalty = 1,
                           repetition_penalty=rept_penalty,       
                           use_cache=True
                          ) 
    output = tokenizer.decode(preds[0].cpu().numpy())
    
    
    #ëª¨ì–‘ ë‹¤ë“¬ê¸°
    output = output.replace('<yun>', '\n\n')
    if '</s>' in output:
        output = output.rstrip('</s>')
    else:
        output = output.splitlines(True)
        output = output[:-1]
        output =''.join(output)
        
    return output



def display():
    
    st.title('AI ì‹œì¸')
    
    #ì‚¬ì´ë“œë°”
    st.sidebar.markdown("# ì˜µì…˜ ì„¤ì • ğŸˆ")
    
    min = st.sidebar.slider(label='ì‹œì˜ ìµœì†Œê¸¸ì´', min_value=50, max_value=150, value=80, step=1)
    max = st.sidebar.slider(label='ì‹œì˜ ìµœëŒ€ê¸¸ì´', min_value=150, max_value=512, value=200, step=1)
    rept_penalty = st.sidebar.slider(label='ë‹¨ì–´ë°˜ë³µ ì œí•œì •ë„', min_value=0.5, max_value=2.0, value=1.2, step=0.1)
   
    
   
    #ì‹œì¸ë³„ ëª¨ë¸ ì„ íƒ
    poet = st.radio('ì›í•˜ëŠ” ì‹œì¸ì„ ì„ íƒí•˜ì„¸ìš”',
                    ('ê¸°ë³¸ëª¨ë¸', 'ìœ¤ë™ì£¼', 'ì´í•´ì¸ ìˆ˜ë…€ë‹˜', 'ë²•ì •ìŠ¤ë‹˜'),
                    horizontal=True)    
    
    model_load(poet)
    
    #í”„ë¡¬í”„íŠ¸
    prompt = st.text_area('', 'ë°©ì•ˆì— ë‚˜ë¹„ê°€')                         
                                                  
    if st.button('ì‹œ ìƒì„±í•˜ê¸°'):
        output = gpt(prompt, min, max, rept_penalty)
        st.code(output.encode().decode('utf-8'), language='python')


    
        
    
 
  
if __name__ == '__main__':
    display()
